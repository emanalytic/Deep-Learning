{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90188a26-2a5e-4211-97a1-15873dbb8c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01894c48-525f-402a-b395-f37adcb62c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1308, 736)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = 'image.jpg'\n",
    "image = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75ec654f-aad7-4e02-aa50-2cb9cbc7d020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input pixels: 962688\n"
     ]
    }
   ],
   "source": [
    "print('input pixels:', 1308 * 736)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1822f7b-20e1-4f4f-b9e4-26c724a5371c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21f6c3f4f90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae42b94a-da15-4d13-b617-3a0a01efd934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21f6c506fd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = cv2.resize(image, (28, 28))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e21bdfb2-ef27-48be-9013-ea650c087a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## normalization\n",
    "image = image / 255.0\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0068630-ed50-44ef-8825-dfc24c066624",
   "metadata": {},
   "source": [
    "\n",
    "* input layer \n",
    "* weigths + biases -> input layer\n",
    "### Forward Pass\n",
    "* hidden layers\n",
    "* activation functions \n",
    "* output layer\n",
    "## Backward Pass\n",
    "* loss function \n",
    "* backpropogation \n",
    "* iterative learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f87207ab-96cd-4084-aef5-8728bdb0559d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we have to flat the pixels like -> 28 * 28 = 784\n",
    "image = image.flatten()\n",
    "image = np.expand_dims(image, axis=1)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15a5f06-b2c8-476b-9af6-55a71d57cf65",
   "metadata": {},
   "source": [
    "##  Weights and Biases\n",
    "\n",
    "In a neural network, every connection between neurons has a weight, which determines the influence one neuron exerts on another. We begin by initializing these weights with small random values.\n",
    "\n",
    "> *I want to observe how the neural network updates the weights through backpropagation, demonstrating its ability to **learn patterns**.*\n",
    "\n",
    "**Dimensions of Weights:**\n",
    "For an input vector `n` (784 for a 28 x 28 image) and a hidden layer with `m` neurons, the weight matrix connecting the input layer to the hidden layer will be sized `m x n`.\n",
    "\n",
    "**Biases:**\n",
    "The bias term is a constant added to the weighted sum of inputs. We typically initialize biases to zero rather than random values to allow the model to focus on learning from the weights without introducing unnecessary variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06cdc5ab-839f-4095-b476-b60de888e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b0035c6-4345-4bd2-904e-653d1652d7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 784)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_w = np.random.randn(neurons, 784) * 0.01 # prevent the network from starting with values that are too large\n",
    "i_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0894d53-5216-4bf1-af85-4c05eb42185c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bh = np.zeros((neurons, 1)) # same as hidden shape \n",
    "bh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9547dfbe-9948-4038-bf3a-be84bf1a0069",
   "metadata": {},
   "source": [
    "## forward pass\n",
    "dot product of input vector and the weight matrix, plus the bias\n",
    "\n",
    "**hidden_layer = Weights_Matrix . Input_Vector + Bias**\\\n",
    "(128, 1) = (128, 784) . (784, 1) + `(128, 1)`\\\n",
    "hidden_layer = (128, 1) + (128, 1)\n",
    "\n",
    "\n",
    "**(Note!)** *matrix addition rules -> if matrix order is same*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eee84942-ab5f-49c2-ad1e-fc5fc189c91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  hidden layer\n",
    "h = np.dot(i_w, image) + bh\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac9dea6-586c-4535-8357-af6d3332f22c",
   "metadata": {},
   "source": [
    "## Activation functions\n",
    "> How they add \"**non-linearity** in models which are basically linear?\"\n",
    "\n",
    "Linear function: `H = W . I + b `\\\n",
    "non-linear function: `H = f(W.I + b)` where `f` is the activation function\\\n",
    "basically we're using this to add a uncertainity in our models instead of constant\\\n",
    "Also they prevent the problems like vanishing and exploding gradients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34ea346-fb07-49f7-a4e8-c8241776c01f",
   "metadata": {},
   "source": [
    "## Perceptron-based network \n",
    "which only output 0 and 1 based on the sign of values not the values itself\n",
    "\n",
    "**Suppose we take all the weights and biases in a network of\n",
    "perceptrons, and multiply them by a positive constant,Show that the behaviour of the network doesn't change**\n",
    "\n",
    "> *c ∑wi. xi +b)* where c is the + constant so according to the output rule the value is positive so it will give 1 and not really effecting the network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c0e14e-4bfd-42a1-9244-67a8740ceb6b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Suppose we have the same setup as the last problem - a network of perceptrons. Suppose also that the overall input to the network of perceptrons has been chosen. We won't need the actual input value; we just need the input to have been fixed. Suppose the weights and biases are such that, for the input to any particular perceptron in the network. Now replace all the perceptrons in the network by sigmoid neurons, and multiply the weights and biases by a positive constant c. Show that in the limit as c approaches infinity, the behavior of this network of sigmoid neurons is exactly the same as the network of perceptrons. How can this fail when for one of the perceptron's?**\n",
    "\n",
    "> So in this case we are using sigmoid activation function which is like $f(c) = 1 / 1 + exp(-c)$ so in this case if we the constant is reaching to +inf the $exp(-inf)$ approaches to 0 therefore the output will be 1. and same in the perceptron based network the output depends on the sign of the weighted sum in that case it always be the + constant and output always be 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d4a5c2-be11-47d3-b5f0-27aa0954ff51",
   "metadata": {},
   "source": [
    "All hidden layers use the same activation function while the output layer uses another activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf7e4412-0f59-4fe1-80fa-e60a50b411a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reLU \n",
    "fh = np.maximum(h, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8e17479-ab2e-4d0a-a3ce-12dfea04c87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output layer \n",
    "n_o = 2 ## binary classification (for the sake of simplicity )\n",
    "w_o = np.random.randn(n_o, neurons) * 0.01 \n",
    "bo = np.zeros((n_o, 1)) \n",
    "bo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7c49045-1894-4855-9b4c-521a3dd8d7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50092796]\n",
      " [0.5007127 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.00164067])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = np.dot(w_o, h) + bo\n",
    "e = 1 + np.exp(-o)\n",
    "y_hat = 1 / e ## sigmoid activation \n",
    "print(y_hat)\n",
    "y_hat[0] + y_hat[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3413f32d-d079-429e-a5ad-b93b4f17f5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6947892164251839"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calculating the loss  \n",
    "y = np.array([[0]])\n",
    "y_pred = np.clip(y_hat, 1e-15, 1 - 1e-15) ## to avoid log(0) = undefined\n",
    "loss = -np.mean(y * np.log(y_pred) + (1 - y)  * np.log(1 - y_pred))\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a0276d-ad03-4f1a-a369-3cbd37efc268",
   "metadata": {},
   "source": [
    "# Backpropogation\n",
    "calculate the gradients of the loss with respect to each weight in the network and update the weights accordingly.\n",
    "\n",
    "**But what are even gradients ??**\n",
    "The rate of change of function w.r.t to its input and the term \"**function**\" represents loss function. So we wanna see how sensitive the loss is to changes in the model’s parameters (weights and biases).. \n",
    "\n",
    "So in this way we have to take partial derivative of loss w.r.t to the model's weights \n",
    "> $∇L= ∂L / ∂wi$\n",
    "​\n",
    "\n",
    "**Partial Derivative**: *It is a derivative where we take the derivative of a function with respect to one variable while keeping all other variables constant.in the context of neural networks, we have a loss function `𝐿` that depends on multiple parameters (like weights `𝑤1,w2,…,𝑤𝑛`).\n",
    "the partial derivative of the loss with respect to a particular weight `𝑤𝑖`  tells us how much the loss will change if we change that specific weight while keeping all other weights constant.*\n",
    "\n",
    "**If this derivative is large, it means small changes to ​will significantly affect the loss. If it’s small, changes to will have little effect on the loss**\n",
    "## Compute Gradients:\n",
    "* Step 01: differentiation of loss function w.r.t to predictions\n",
    "* Step 02: using chain rule because predicted ouput y_hat is influenced by weights here we have composite function (simply function in function) that's why we are applying chain rule in order to calculate the derivative\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417276c6-12e6-430b-8970-33a992e3f660",
   "metadata": {},
   "source": [
    "\n",
    "$$ \n",
    "\\frac{\\partial L}{\\partial w_i} = \\frac{\\partial \\hat{y}}{\\partial L} \\cdot \\frac{\\partial w_i}{\\partial \\hat{y}}\n",
    "$$\n",
    "> Here, first part represents how the loss changes with respect to the predictions, and second portion shows how changes in the weights affect the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a4f5d0-c95b-42d1-9f39-bb060fb2d55e",
   "metadata": {},
   "source": [
    "(**Note!**) *Differentiation is the process of finding the derivative of function while **derivative** is the result of differentiation*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14f82c4-1cea-46ac-9fa3-9f666ee5fdab",
   "metadata": {},
   "source": [
    "\n",
    "so in neural network that's how we gonna proceed\n",
    "1. gradient of loss w.r.t to prediction \n",
    "2. Calculate the gradients of output layer (its activation function and weights + biases)\n",
    "3. gradients of hidden layer(w.r.t weights and biases of that hidden layer)\\\n",
    "**(it will tell how much the output layer's predictions  and hidden layer output contributed to the loss)**\n",
    "4. Update the weight and biases to the point when we reach global minimun of our cost function. (gradient descent)\n",
    "\n",
    "\n",
    "\n",
    "gonna use `autograd` lib here to calculate the derivatives because i already know how to calculate them :> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "416b4009-e493-4e1a-8e34-e499b933fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8beedba-3529-4709-8e54-8bbd2d0ae18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd import numpy as anp\n",
    "from autograd import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23092977-ee0b-496d-909d-60f4699dc359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.00371875],\n",
       "       [2.00285488]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## w.r.t to y_pred\n",
    "d_y_pred = -(y / y_pred) + (1 - y) / (1 - y_pred)\n",
    "d_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cee9beb0-1dcc-40ad-a84a-2bdd71f6f07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50092796],\n",
       "       [0.5007127 ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for output layer\n",
    "d_o = d_y_pred * (y_hat * (1 - y_hat)) ## derivative of sigmoid)\n",
    "d_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db15be69-b9fc-412c-8461-11fb12099c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for weights and biases in output layer\n",
    "d_w_o = anp.dot(d_o, h.T)\n",
    "d_bo = d_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae0b66d6-2336-4e3b-8a47-ed30ccd4ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient for the hidden layer (using ReLU derivative)\n",
    "d_h = anp.dot(w_o.T, d_o)\n",
    "d_h[h <= 0] = 0  # relu derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e54dced-9cc9-4058-91a1-56a2ccc89c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradients for input layer weights and biases\n",
    "d_i_w = anp.dot(d_h, image.T)\n",
    "d_b_h = d_h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3bd05f-ce69-48fa-9f32-4cd0a9c79a7a",
   "metadata": {},
   "source": [
    "## Connecting Learning Rate and Cauchy-Schwarz Inequality\n",
    "\n",
    "**Learning Rate**: In gradient descent, the learning rate (or step size) is how much you adjust your position based on the gradient. It's like saying, \"I'm going to move this much in the direction that decreases my function.\"\n",
    "\n",
    "**Cauchy-Schwarz Inequality**: This inequality helps us understand limits when dealing with vectors, like the gradient and our movement direction. It tells us that the way we combine these vectors (like how we move) has certain boundaries.\n",
    "\n",
    "*When you're moving based on the gradient, you want to ensure you're not taking too big of a step that could mess up your search for the minimum. The Cauchy-Schwarz inequality helps provide that framework to know what’s a reasonable move.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3290f3f-0027-463a-a1ba-1e1541dff63d",
   "metadata": {},
   "source": [
    "\n",
    "### **Cauchy-Schwarz Inequality**\n",
    "\n",
    "The Cauchy-Schwarz inequality tells us about the relationship between vectors, specifically:\n",
    "\n",
    "$$  \n",
    "\\mathbf{u} \\cdot \\mathbf{v} \\leq \\| \\mathbf{u} \\| \\|\\mathbf{v}\\| \n",
    "$$\n",
    "\n",
    "suppose we have two lists of numbers(two vectors):\n",
    "\n",
    "List A: [2,3]\\\n",
    "List B: [4,5]\n",
    "\n",
    "First, we calculate the left side of the Cauchy-Schwarz inequality, which is the sum of the products of corresponding elements(dot product of vectors) from both lists:\n",
    "$(2⋅4) + (3⋅5)= 8+15=23$\n",
    "\n",
    "now the right side which involves finding the sum of squares of each list \n",
    "\n",
    "for list A\\\n",
    "$2^2 + 3^2 = 4+9=13$\n",
    "\n",
    "for list B\\\n",
    "$4^2 + 5^2 = 16 + 25 = 41$\n",
    "\n",
    "multiply these two sums \n",
    "$13 . 41 = 533$\n",
    "\n",
    "according to cauchy schwarz inequality the square of the sum of products should be less than or equal to the product of sum of the squares\\\n",
    "$(23)^2 \\leq 533$ where $(23)^2 = 529$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e131dd-e94a-4d75-82cb-b191fb13569e",
   "metadata": {},
   "source": [
    "### **Limits of the Learning Rate**\n",
    "\n",
    "- **Too Small**: If your learning rate is very small you will take tiny steps while this can ensure stability and precision it means that convergence to the minimum will be very slow and result in long training times especially in large datasets or complex models\n",
    "\n",
    "- **Too Large**: if the learning rate is too large you risk overshooting the minimum so instead of converging to the lowest point of the function it might bounce back and forth across it or even diverge, meaning your function values keep increasing instead of decreasing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7b424d-5c0a-4bc4-9155-202eaec0cdc5",
   "metadata": {},
   "source": [
    "In terms of gradient descent:\n",
    "\n",
    "- **Vector Direction**: The gradient $\\nabla f(x)$ indicates the direction of the steepest ascent. Moving in the opposite direction (for minimization) means taking a step toward reducing the function value.\n",
    "\n",
    "\n",
    "- **Magnitude of Step**: When you apply the learning rate to the gradient, you're effectively scaling the gradient vector. The Cauchy-Schwarz inequality suggests that the size of your movement (step) should respect the relationship between the gradient's size and direction. This prevents taking steps that are disproportionate to the gradient's direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29d73189-fc16-445e-841c-0253288fa332",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001 ## learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe8ea98a-853c-469d-bfa5-ac99b26fb921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update parameters\n",
    "\n",
    "i_w -= lr * d_i_w\n",
    "bh -= lr * d_b_h\n",
    "w_o -= lr * d_w_o\n",
    "bo -= lr * d_bo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e8ae1e-af1c-422e-b471-205ce6e7633e",
   "metadata": {},
   "source": [
    "tadaa!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b21c22-2cec-49d7-bdc5-fa42d13c4a26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
